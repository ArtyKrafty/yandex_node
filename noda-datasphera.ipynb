{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellId": "3mabao31ofeski3fuc3qzi"
   },
   "outputs": [],
   "source": [
    "inputs = [\"https://drive.google.com/uc?id=1ki7iNkXGdQ7lSmnze5Ox9CPzHWvvtCQ_\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellId": "xddzsl2taleae5g8a46ear"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading config.json: 100%|██████████| 753/753 [00:00<00:00, 368kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 932M/932M [00:15<00:00, 62.3MB/s] \n",
      "Downloading spiece.model: 100%|██████████| 808k/808k [00:00<00:00, 8.27MB/s]\n",
      "Downloading special_tokens_map.json: 100%|██████████| 65.0/65.0 [00:00<00:00, 36.2kB/s]\n",
      "Downloading tokenizer_config.json: 100%|██████████| 315/315 [00:00<00:00, 185kB/s]\n",
      "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:83: UserWarning: HIP initialization: Unexpected error from hipGetDeviceCount(). Did you run some cuda functions before calling NumHipDevices() that might have already set an error? Error 101: hipErrorInvalidDevice (Triggered internally at  ../c10/hip/HIPFunctions.cpp:110.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "# https://huggingface.co/cointegrated/rut5-base-absum \n",
    "\n",
    "def summarize(tokenizer, model,\n",
    "    text, n_words=None, compression=None,\n",
    "    max_length=1000, num_beams=3, do_sample=False, repetition_penalty=10.0, \n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Summarize the text\n",
    "    The following parameters are mutually exclusive:\n",
    "    - n_words (int) is an approximate number of words to generate.\n",
    "    - compression (float) is an approximate length ratio of summary and original text.\n",
    "    \"\"\"\n",
    "    if n_words:\n",
    "        text = '[{}] '.format(n_words) + text\n",
    "    elif compression:\n",
    "        text = '[{0:.1g}] '.format(compression) + text\n",
    "    x = tokenizer(text, return_tensors='pt', padding=True).to(model.device)\n",
    "    with torch.inference_mode():\n",
    "        out = model.generate(\n",
    "            **x, \n",
    "            max_length=max_length, num_beams=num_beams, \n",
    "            do_sample=do_sample, repetition_penalty=repetition_penalty, \n",
    "            **kwargs\n",
    "        )\n",
    "    return tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "def summarize_news(input: List[str]) -> List:\n",
    "    '''суммаризация'''\n",
    "    MODEL_NAME = 'cointegrated/rut5-base-absum'\n",
    "    model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "    tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    preds = []\n",
    "    news = pd.read_csv(input[0])[\"inputs\"].tolist()\n",
    "    for rec in news:\n",
    "        summary = summarize(tokenizer, model, rec)\n",
    "        preds.append(summary)\n",
    "\n",
    "    return preds\n",
    "\n",
    "outputs = summarize_news(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellId": "ovtbbq3egzfp054u1r6t"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Встреча началась с песенки о дружбе. Участники встречи отвечали на вопросы викторины, рассказывали пословицы о дружбе.',\n",
       " 'Амурский тигр и дальневосточный леопард спасены от угрозы полного исчезновения.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellId": "u2t39sp7e0icbuf1dxarld"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registry username: json_key\n",
      "Secret name of password: docker\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pushing image: layers = 4/4, pushed = 9.273/9.273 GB                          "
     ]
    }
   ],
   "source": [
    "#!:docker-publish noda_clone:1.0.1 cr.yandex/crp6ermefad6f9dc0jbr:noda"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "notebookId": "2dc240fc-112c-4520-9bb3-80027cfd6f2d",
  "notebookPath": "noda.ipynb",
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
